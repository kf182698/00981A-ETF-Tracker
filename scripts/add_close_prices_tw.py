#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¾æ“š data/ ä¸‹ã€Œæœ¬æ¬¡è®Šå‹•çš„ CSV æ¸…å–®ã€ï¼Œæ–°å¢ž/è¦†è“‹ã€Œæ”¶ç›¤åƒ¹ã€æ¬„ä½ã€‚
è³‡æ–™ä¾†æºåƒ…å®˜æ–¹ï¼š
- TWSE æœˆè¡¨ STOCK_DAYï¼ˆJSONï¼‰
- è‹¥è©²ä»£è™Ÿè©²æœˆæŸ¥ç„¡ï¼šå‚™æ´ TPEx ã€Œæ¯æ—¥æ”¶ç›¤è¡¨ã€CSV
è¦å‰‡ï¼š
- åŒæ—¥å€¼ä¸€å¾‹è¦†è“‹ (--overwrite-same-day)
- ç•¶æ—¥ç„¡æ”¶ç›¤åƒ¹å‰‡å¾€å‰å›žè£œï¼Œæœ€å¤š --max-backdays å¤©ï¼ˆé è¨­ 15ï¼‰
- ä»ç„¡å‰‡ NAï¼ˆç©ºå€¼ï¼‰
ä¸æ”¹å‹• daily_fetch.ymlï¼›æ­¤è…³æœ¬ç”±ç¨ç«‹ workflow åœ¨ data æœ‰æ–° CSV push å¾ŒåŸ·è¡Œã€‚
"""

import argparse
import io
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import pandas as pd
import requests
from dateutil import tz, parser as dtparser

TPE_TZ = tz.gettz("Asia/Taipei")
HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; ClosePriceBot/1.0; +https://github.com/)",
    "Accept": "application/json, text/plain, */*",
}

# å®˜æ–¹ç«¯é»žï¼ˆé›†ä¸­ç®¡ç†ï¼Œè‹¥æœªä¾†èª¿æ•´åªéœ€æ”¹æ­¤è™•ï¼‰
TWSE_STOCK_DAY = "https://www.twse.com.tw/exchangeReport/STOCK_DAY"
TPEX_DAILY_CSV = "https://www.tpex.org.tw/en/stock/aftertrading/DAILY_CLOSE_quotes/stk_quote_download.php"

DATE_RE_YYYYMMDD = re.compile(r"^\d{8}$")
DATE_RE_ISO = re.compile(r"^\d{4}-\d{2}-\d{2}$")

def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument("--csv-list-file", required=True, help="æœ¬æ¬¡éœ€è™•ç† CSV æ¸…å–®æª”ï¼ˆæ¯è¡Œä¸€å€‹è·¯å¾‘ï¼‰")
    ap.add_argument("--max-backdays", type=int, default=15, help="å¾€å‰å›žè£œå¤©æ•¸ä¸Šé™ï¼ˆé è¨­ 15ï¼‰")
    ap.add_argument("--overwrite-same-day", action="store_true", help="åŒæ—¥å€¼ä¸€å¾‹è¦†è“‹")
    return ap.parse_args()

def _read_changed_list(path: str) -> List[str]:
    with open(path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

def _guess_report_date_from_filename(path: str) -> Optional[datetime]:
    base = os.path.basename(path)
    name, _ = os.path.splitext(base)
    if DATE_RE_ISO.match(name) or DATE_RE_YYYYMMDD.match(name):
        return dtparser.parse(name).replace(tzinfo=TPE_TZ)
    return None

def _ensure_code(s: str) -> str:
    s = s.strip().replace(".TW", "").replace(".TWO", "")
    return s.zfill(4) if s.isdigit() else s

# ---------------------- TWSE ----------------------

def fetch_twse_month_json(stock_no: str, any_day: datetime) -> Optional[dict]:
    # å–è©²æ—¥æ‰€åœ¨æœˆçš„æœˆè¡¨ï¼ˆä¸€æ¬¡æ‹¿æ•´æœˆï¼‰
    date_param = f"{any_day.year}{any_day.month:02d}01"
    params = {"response": "json", "date": date_param, "stockNo": stock_no}
    try:
        resp = requests.get(TWSE_STOCK_DAY, params=params, headers=HEADERS, timeout=20)
        if resp.status_code != 200:
            return None
        js = resp.json()
        if js.get("data"):
            return js
        return None
    except Exception:
        return None

def parse_twse_close_map(js: dict) -> Dict[str, float]:
    out: Dict[str, float] = {}
    rows = js.get("data", [])
    for row in rows:
        if len(row) < 7:
            continue
        raw_date = str(row[0]).strip()
        close_str = str(row[6]).replace(",", "").strip()
        # å¯èƒ½ç‚º 2025/09/08 æˆ– 114/09/08ï¼ˆæ°‘åœ‹ï¼‰
        parts = raw_date.split("/")
        try:
            if len(parts) == 3:
                y = int(parts[0]); m = int(parts[1]); d = int(parts[2])
                if y < 1911:
                    y += 1911
                dt = datetime(y, m, d, tzinfo=TPE_TZ)
            else:
                dt = dtparser.parse(raw_date).astimezone(TPE_TZ)
        except Exception:
            continue
        try:
            close = float(close_str)
        except ValueError:
            continue
        out[dt.date().isoformat()] = close
    return out

# ---------------------- TPEx ----------------------

def fetch_tpex_daily_csv(date_dt: datetime) -> Optional[pd.DataFrame]:
    """ä¸‹è¼‰ TPEx è©²æ—¥çš„æ¯æ—¥æ”¶ç›¤ CSVï¼ˆè‹±æ–‡ç«™ï¼‰ã€‚"""
    roc_y = date_dt.year - 1911
    roc_date = f"{roc_y:03d}/{date_dt.month:02d}/{date_dt.day:02d}"
    params = {"d": roc_date}
    try:
        resp = requests.get(TPEX_DAILY_CSV, params=params, headers=HEADERS, timeout=30)
        if resp.status_code != 200 or not resp.text.strip():
            return None
        content = resp.content.decode("utf-8", errors="ignore")
        df = pd.read_csv(io.StringIO(content))
        # æ¬„åçµ±ä¸€åŽ»ç©ºç™½
        df.columns = [str(c).strip() for c in df.columns]
        return df
    except Exception:
        return None

def build_tpex_code_close_map(df: pd.DataFrame) -> Dict[str, float]:
    code_col = None
    close_col = None
    for c in ["è­‰åˆ¸ä»£è™Ÿ", "ä»£è™Ÿ", "Code", "Symbol"]:
        if c in df.columns:
            code_col = c; break
    for c in ["æ”¶ç›¤", "æ”¶ç›¤åƒ¹", "Closing Price", "Close"]:
        if c in df.columns:
            close_col = c; break
    if code_col is None or close_col is None:
        return {}
    out: Dict[str, float] = {}
    for _, row in df.iterrows():
        code = _ensure_code(str(row[code_col]))
        try:
            close = float(str(row[close_col]).replace(",", ""))
        except ValueError:
            continue
        out[code] = close
    return out

# ---------------- å…ˆ TWSE â†’ å† TPExã€æœ€å¤šå›žè£œ N å¤© ----------------

def get_close_price_for_code(code: str, target_date: datetime, max_backdays: int,
                             tpex_cache: Dict[str, Dict[str, float]]) -> Tuple[Optional[float], Optional[str]]:
    code = _ensure_code(code)
    for i in range(max_backdays + 1):
        day = (target_date - timedelta(days=i)).astimezone(TPE_TZ)
        dkey = day.date().isoformat()

        # 1) TWSEï¼šè©²æœˆæœˆè¡¨
        js = fetch_twse_month_json(code, day)
        if js:
            m = parse_twse_close_map(js)
            if dkey in m:
                return m[dkey], dkey

        # 2) TPExï¼šè©²æ—¥æ•´æ‰¹ CSVï¼ˆå¿«å–é¿å…é‡æŠ“ï¼‰
        if dkey not in tpex_cache:
            df = fetch_tpex_daily_csv(day)
            tpex_cache[dkey] = build_tpex_code_close_map(df) if df is not None else {}
        mp = tpex_cache.get(dkey, {})
        if code in mp:
            return mp[code], dkey

    return None, None

# ---------------- ä¸»æµç¨‹ï¼šè™•ç†å–®ä¸€ CSV ----------------

def process_csv(path: str, max_backdays: int, overwrite_same_day: bool) -> bool:
    # è®€æª”
    df = pd.read_csv(path, dtype=str)

    # ðŸ‘‰ C çš„æ¬„åæ¸…æ´—ï¼šåŽ» BOM èˆ‡ç©ºç™½ï¼Œé¿å…æ‰¾ä¸åˆ°ã€Œè‚¡ç¥¨ä»£è™Ÿã€
    df.columns = [str(c).replace("\ufeff", "").strip() for c in df.columns]

    # æ‰¾ä»£è™Ÿæ¬„ä½ï¼ˆå¤šç¨®å¸¸è¦‹å¯«æ³•ï¼‰
    code_col = None
    for c in ["è‚¡ç¥¨ä»£è™Ÿ", "ä»£è™Ÿ", "è­‰åˆ¸ä»£è™Ÿ", "code", "Code", "è‚¡ç¥¨ä»£ç¢¼", "è­‰åˆ¸ä»£ç¢¼"]:
        if c in df.columns:
            code_col = c; break
    if code_col is None:
        print(f"[WARN] {path} æ‰¾ä¸åˆ°è‚¡ç¥¨ä»£è™Ÿæ¬„ä½ï¼Œç•¥éŽã€‚")
        return False

    # ç›®æ¨™æ—¥ï¼šå„ªå…ˆæª”åè§£æžï¼Œå¦å‰‡ä»Šå¤©ï¼ˆå°åŒ—ï¼‰
    rpt_dt = _guess_report_date_from_filename(path)
    if rpt_dt is None:
        rpt_dt = datetime.now(TPE_TZ)

    # æº–å‚™æ”¶ç›¤åƒ¹æ¬„
    if "æ”¶ç›¤åƒ¹" not in df.columns:
        df["æ”¶ç›¤åƒ¹"] = pd.NA

    codes = df[code_col].astype(str).map(_ensure_code).tolist()
    tpex_cache: Dict[str, Dict[str, float]] = {}

    print(f"[INFO] Processing {path} (target={rpt_dt.date().isoformat()})")

    changed = False
    for idx, code in enumerate(codes):
        old_val = df.at[idx, "æ”¶ç›¤åƒ¹"]
        price, got_date = get_close_price_for_code(code, rpt_dt, max_backdays, tpex_cache)

        if price is not None:
            # åŒæ—¥è¦†è“‹ï¼›å…¶ä»–æƒ…æ³ï¼šç©ºå€¼æ‰å¡«
            if pd.isna(old_val) or overwrite_same_day:
                df.at[idx, "æ”¶ç›¤åƒ¹"] = price
                changed = True
            print(f"[OK] {code} -> {price} (date={got_date})")
        else:
            print(f"[MISS] {code} -> NA (no price within {max_backdays} days)")

    if changed:
        df.to_csv(path, index=False, encoding="utf-8-sig")
        print(f"[INFO] Updated: {path}")
    else:
        print(f"[INFO] No change for: {path}")
    return changed

def main():
    args = parse_args()
    csv_paths = _read_changed_list(args.csv_list_file)
    any_changed = False
    for p in csv_paths:
        if not os.path.exists(p):
            print(f"[WARN] Not found: {p}")
            continue
        chg = process_csv(p, max_backdays=args.max_backdays, overwrite_same_day=args.overwrite_same_day)
        any_changed = any_changed or chg
    if not any_changed:
        print("[INFO] No CSV updated.")

if __name__ == "__main__":
    main()
